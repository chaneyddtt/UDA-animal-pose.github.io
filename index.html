
<!-- saved from url=(0047)https://www.cs.cmu.edu/~peiyunh/tiny/index.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="StyleSheet" href="./files/style.css" type="text/css" media="all">

    <title>From Synthetic to Real: Unsupervised Domain Adaptationfor Animal Pose Estimation</title>

    <style type="text/css">
      body {
	    font-family : Times;
	    background-color : #f2f2f2;
	    font-size : 15px;
      }

      .content {
	    width : 800px;
	    padding : 25px 25px;
	    margin : 25px auto;
	    background-color : #fff;
	    border-radius: 20px;
      }
      .description {
        font-family: "Times";
        white-space: pre;
        text-align: left;
      }

      .content-title {
	    background-color : inherit;
      margin-top: 5px;
      padding-top: 5px;
	    margin-bottom : 0;
	    padding-bottom : 0;
      }

      a, a:visited {
	    text-decoration: none;
	    color : blue;
      }

      .anchor {
      color: inherit;
      }
      #authors {
	    text-align : center;
      }

      #conference {
	    text-align : center;
	    font-style : italic;
      }

      #authors a {
	    margin : 0 10px;
      }

      h1 {
	    text-align : center;
	    font-family : Times;
	    font-size : 35px;
      }

      h2 {
	    font-family : Times;
	    font-size : 25px;
	    padding : 0; margin : 10px;
      }

      h3 {
	    font-family : Times;
	    font-size : 20px;
	    padding : 0; margin : 10px;
      }

      p {
	    font-family : Times;
	    line-height : 130%;
	    margin : 10px;
      }

      big {
	    font-family : Times;
	    font-size : 20px;
      }

      li {
	    margin : 10px 0;
      }

      .samples {
	    float : left;
	    width : 50%;
	    text-align : center;
      }

      .cond {
	    float : left;
	    margin : 0 40px;
      }

      .cond-container {
	    width : 700px;
	    margin : 0 auto;
	    text-align : center;
      }
     #vidalign {
         display: block;
         margin: 0px;
         padding: 0px;
         position: relative;
         top: 90px;
         height: auto;
         max-width: auto;
         overflow-y: hidden;
         overflow-x:auto;
         word-wrap:normal;
         white-space:nowrap;
     }

    </style>

  </head>



  <body>

    <div class="content content-title" style="text-align: center;">
	    <h1>From Synthetic to Real: Unsupervised Domain Adaptationfor Animal Pose Estimation</h1>
	<big style="color:grey;">
                    CVPR 2021
        </big>    
	<p id="authors">
      <table align="center" style="width:100%; text-align:center; table-layout: fixed">
        <tr>
	      <th><a href="https://chaneyddtt.github.io/">Chen Li</a></th>
	      <th><a href="https://www.comp.nus.edu.sg/~leegh/">Gim Hee Lee</a></th>
        </tr>
      </table>
      <table align="center" style="width:100%; text-align:center; table-layout: fixed">
        <th>Department of Computer Science, National University of Singapore</th>
      </table>
	    </p>
	    <p>
	    </p>
    </div>




    <div class="content">
      <figure style="font-family: Times; font-weight: normal; margin: 0px; padding: 0px; border: 0px; text-align: left">
         <video playsinline controls autoplay loop muted width="400" height="225">
          <source  src="./files/video4.mp4" type="video/mp4">
         </video>
	 <video playsinline controls autoplay loop muted width="400" height="225">
          <source  src="./files/video5.mp4" type="video/mp4">
         </video>     
	      
         <br>
	      <figcaption> Many existing approaches on nonrigid shape reconstruction heavily rely on category-specific 3D shape templates, such as SMPL for human and SMAL for quadrupeds. In contrast, LASR jointly recovers the object shape, articulation and camera parameters from a monocular video without using category-specific shape templates. By combining generic shape and motion priors with differentiable rendering, LASR applies to a wide range of nonrigid shapes and obtains faithfull 3D reconstruciotn.
      </figure>
    </div>
    
    
    <div class="content">
      <h2>Abstract</h2>
      <p>
        Animal pose estimation is an important field that has received increasing attention in the recent years.  
	      The main challenge for this task is the lack of labeled data.   
	      Existing works circumvent this problem with pseudo labels generated from data of other easily accessible domains such as synthetic data.  
	      However, these pseudo labels are noisyeven with consistency check or confidence-based filtering due to the domain shift in the data.
	      To solve this problem, we design a multi-scale domain adaptation module(MDAM) to reduce the domain gap between the syntheticand real data. 
	      We further introduce an online coarse-to-fine pseudo label updating strategy.   
	      Specifically, we propose a self-distillation module in an inner coarse-update loop and a mean-teacher in an outer fine-update loop to generate new pseudo labels that gradually replace the old ones.
	      Consequently, our model is able to learn from the old pseudo labels at the early stage, and gradually switch to the new pseudo labels to prevent overfitting in the later stage. 
	      We evaluate our approach on the TigDog and VisDA2019 datasets, where we outperform existing approaches by a large margin.   
	      We also demonstrate the generalization ability of our model by testing extensively on both unseen domains and unseen animal categories.  
	      Our code is avail-able at the project website.
	    </p>
      <div id="teaser" style="margin: 12px; text-align: left;border-top: 1px solid lightgray;padding-top: 12px;">
	<a href="https://arxiv.org/pdf/2103.14843.pdf">
	        <strong>[Paper]</strong>
	      <a href="https://github.com/chaneyddtt/UDA-Animal-Pose">           
	        <strong>[Code]</strong>
	      </a>           
	        <strong>[Slides]</strong>
	      </a>           
      </div>
    </div>
 
<!--
    <div class="content">
            <h2>Bibtex</h2>
            <p class="description">@inproceedings{yang2021lasr,
  title={LASR: Learning Articulated Shape Reconstruction from a Monocular Video},
  author={Yang, Gengshan 
      and Sun, Deqing
      and Jampani, Varun
      and Vlasic, Daniel
      and Cole, Forrester
      and Chang, Huiwen
      and Ramanan, Deva
      and Freeman, William T
      and Liu, Ce},
  booktitle={CVPR},
  year={2021}
}  </p>
    </div>
-->
	    
    <div class="content">
      <div style="float: right; width:70px; margin-top: 0px; margin-bottom: 25px">
      </div>
      <h2>Video</h2>
         <video controls width="810" height="520">
          <source  src="./files/cvpr2021_video.mp4" type="video/mp4">
         </video>
    </div>

    <div class="content">
      <div style="float: right; width:70px; margin-top: 0px; margin-bottom: 25px">
      </div>
      <h2>Results on DAVIS</h2>
        <h3> Dance-twirl </h3>
        <div>
         <video playsinline controls autoplay muted loop width="49%">
          <source  src="./files/results/video1.mp4" type="video/mp4">
         </video>
         <video playsinline controls autoplay muted loop width="49%">
          <source  src="./files/results/video2.mp4" type="video/mp4">
         </video>
         </div>
        
    </div>

   

  
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tr><td>
    <p align="right"><font size="2">
        <a href="https://lasr-google.github.io/">Webpage design borrowed from LASR</a> </font>
    </p>
</td></tr>
</table>

</body></html> 
